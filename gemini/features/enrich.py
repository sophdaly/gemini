"""
Enrich input images with features generated by pretrained FaceNet
"""

from gemini.features.facenet import FaceNet
from collections import Counter
import tensorflow as tf
import pandas as pd
import argparse
import time
import sys
import os


FLAGS = None


def _import_lfw_data(data_path):
    """
    Import LFW dataset and process into (image, label) format
    """
    labels = []
    images = []

    # Dir names represent labels
    unique_labels = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]

    # Loop through directories importing images and labels
    for lab in unique_labels:
        path= os.path.join(data_path, lab)
        image_names = os.listdir(path)
        image_paths = [os.path.join(path, img) for img in image_names]

        for image in image_paths:
            images.append(image)
            labels.append(lab)

    assert len(images) == len(labels), "Error: Wtf your images and labels don't match?"

    labels_with_multiple_samples = [lab for lab, count in Counter(labels).items() if count > 1]

    print("Total labels: {}".format(len(unique_labels)))
    print("Total images: {}".format(len(images)))
    print("Total labels with more that one image samples: {}".format(len(labels_with_multiple_samples)))

    return images, labels


def main(_):

    t0 = time.time()

    # Import images to enrich
    images, labels = _import_lfw_data(data_path=FLAGS.input_data_path)

    with tf.Session() as sess:

        # Load pretrained FaceNet
        facenet = FaceNet(sess=sess, model_path=FLAGS.model_path, verbose=FLAGS.print_data)

        # Enrich images with FaceNet embeddings
        print("Enriching images")

        embeddings = facenet.enrich(images=images, batch_size=FLAGS.batch_size)
        print("{} images enriched [timer: {:.2f}s]".format(len(embeddings), time.time() - t0))

    # Output images, embeddings and labels to file
    df = pd.DataFrame.from_dict(
        {
            'image': images,
            'label': labels,
            'embedding': embeddings
        }
    )

    df.to_csv(FLAGS.output_features_file, index=False)

    print("Features dataframe written to file: {}".format(FLAGS.output_features_file))


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_path', type=str, default='models/vggface2',
                        help='Path to pretrained FaceNet model directory')
    parser.add_argument('--input_data_path', type=str, default='data/raw/lfw-deepfunneled',
                        help='Path to input image data directory')
    parser.add_argument('--output_features_file', type=str, default='data/features/data.csv',
                        help='Path to output feature data directory')
    parser.add_argument('--batch_size', type=int, default=50,
                        help='Batch size')
    parser.add_argument('--print_data', action='store_true',
                        help='Print restored data')

    FLAGS, unparsed = parser.parse_known_args()
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
